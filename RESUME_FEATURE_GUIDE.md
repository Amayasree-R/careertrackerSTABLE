# Resume Upload & Resume Intelligence Feature - Implementation Guide

## âœ… Features Implemented

### 1. **User Model Extensions** âœ“
Located: `server/models/User.js`

Extended the User schema with:
- **Career Information Fields:**
  - `roleType` (enum: student, employed, unemployed)
  - `collegeName`, `degree`, `graduationYear`
  - `currentCompany`, `previousCompanies`
  - `yearsOfExperience`, `primaryTechStack`, `targetJobRole`

- **Resume File Tracking:**
  - `resumeFile`: {filename, uploadedAt, filePath}

- **Parsed Resume Data:**
  - `resumeData`: {skills, tools, projects, experience, education, certifications, rawText, parsedAt}

- **Skill Analysis Results:**
  - `skillAnalysis`: {matchingSkills, missingSkills, suggestedSkills, industryDemandSkills, analysisDate}

### 2. **PDF Upload Endpoint** âœ“
Route: `POST /api/resume/upload`

Features:
- Accepts PDF files only (validated via multer)
- 5MB file size limit
- Secure file storage in `uploads/resumes/` directory
- Automatic text extraction and parsing
- Returns parsed resume data with email/phone extraction

### 3. **Resume Parsing Service** âœ“
File: `server/services/resumeParserService.js`

Capabilities:
- **PDF Text Extraction:** Uses pdf-parse library
- **OCR Fallback:** Falls back to Tesseract if PDF extraction insufficient
- **Section Detection:** Automatically identifies:
  - Skills & Tools
  - Work Experience
  - Education
  - Projects
  - Certifications
- **Data Cleaning:** Normalizes text, removes bullet points, handles special characters
- **Smart Parsing:**
  - Company/Role extraction
  - Duration parsing (handles various date formats)
  - Email/Phone extraction
  - URL extraction
  - Tech stack detection from project descriptions

### 4. **Resume Data Storage** âœ“
MongoDB Storage Structure:
```javascript
{
  skills: [String],           // Normalized technical skills
  tools: [String],            // Tools & technologies
  projects: [
    { title, description, techStack, _id: false }
  ],
  experience: [
    { company, role, duration, description, _id: false }
  ],
  education: [
    { institution, degree, field, year, _id: false }
  ],
  certifications: [
    { name, issuer, date, _id: false }
  ],
  rawText: String,            // Extracted raw text (for debugging)
  parsedAt: Date              // Timestamp of parsing
}
```

### 5. **Skill Normalization Service** âœ“
File: `server/utils/skillNormalizer.js`

Features:
- Normalizes 100+ skill variations to standard names
- Supports:
  - Language variants (JSâ†’JavaScript, Pyâ†’Python, etc.)
  - Framework aliases
  - Database name variations
  - Cloud platform names
- Skill categorization (languages, frameworks, databases, cloud, devTools)
- Extracts skills from text using keyword matching

### 6. **Skill Gap Analysis Service** âœ“
File: `server/services/resumeAnalyzerService.js`

Capabilities:
- **Industry Demand Analysis:** Uses GitHub API to fetch trending skills
- **Search Queries:** Generates AI-assisted search queries for job roles
- **Skill Matching:** Compares user skills against industry demands
- **Gap Analysis:** Identifies matching, missing, and suggested skills
- **Learning Recommendations:** Categorizes skills as critical, important, nice-to-have
- **Roadmap Generation:** Creates 4-phase learning plan (0-2mo, 2-4mo, 4-6mo, 6+mo)
- **Related Skills:** Suggests complementary skills

### 7. **Resume API Controller** âœ“
File: `server/routes/resumeController.js`

Endpoints Implemented:
- `uploadAndParseResume()` - Upload & auto-parse
- `analyzeResume()` - Run skill gap analysis
- `getResumeData()` - Fetch parsed resume
- `updateResumeData()` - Manual editing support
- `deleteResume()` - Clean up resume data
- `getSkillAnalysis()` - Get analysis results

### 8. **Resume Routes** âœ“
File: `server/routes/resume.js`

API Endpoints:
```
POST   /api/resume/upload              - Upload PDF
POST   /api/resume/analyze             - Run analysis
GET    /api/resume/:userId             - Get resume data
PUT    /api/resume/:userId             - Update data
DELETE /api/resume/:userId             - Delete resume
GET    /api/resume/:userId/analysis    - Get analysis
```

### 9. **Utility Functions** âœ“

**Text Cleaning** (`server/utils/textCleaner.js`):
- Whitespace normalization
- Special character removal
- Line extraction & filtering
- Section detection with regex patterns
- Duration parsing
- Email/Phone/URL extraction

**Skill Normalization** (`server/utils/skillNormalizer.js`):
- 100+ skill mappings
- Skill categorization
- Text-based skill extraction
- Deduplication

### 10. **Frontend Components** âœ“

#### ResumeDashboard (Main Component)
Features:
- Tab-based interface (Upload â†’ Preview â†’ Analysis)
- State management for resume data
- Error handling
- Loading states
- Integration with all sub-components

#### ResumeUploadForm
Features:
- Drag-and-drop support
- File validation (PDF only, â‰¤5MB)
- Upload progress
- Success/error messages
- Helpful instructions

#### ResumePreview
Features:
- View all parsed sections
- **Edit Mode:**
  - Edit individual skills
  - Edit work experience details
  - Edit education info
  - Edit projects & certifications
  - Add/remove items
  - Save changes back to server
- Delete resume functionality
- Trigger skill analysis

#### SkillGapAnalysis
Features:
- Visual match percentage indicator
- Progress bar
- Matched vs Missing skills display
- Learning recommendations (Critical/Important/Nice-to-Have)
- Industry demand comparison
- Improvement tips

#### SkillRoadmap
Features:
- 4-phase learning roadmap visualization
- Phase-based skill grouping
- Timeline overview
- Color-coded phases
- Success tips & strategies

## ğŸš€ Installation & Setup

### 1. Install Dependencies
```bash
cd server
npm install
```

This installs:
- `multer` - File upload handling
- `pdf-parse` - PDF text extraction
- `tesseract.js` - OCR fallback
- `sharp` - Image processing

### 2. Update Environment Variables
Ensure `.env` has:
```env
MONGODB_URI=mongodb+srv://...
PORT=5000
GITHUB_TOKEN=ghp_...  # For industry skill fetching
```

### 3. Server Setup
The resume routes are automatically registered in `server/index.js`:
```javascript
import resumeRoutes from './routes/resume.js'
app.use('/api/resume', resumeRoutes)
```

### 4. Frontend Usage

Import and use the ResumeDashboard component:
```jsx
import ResumeDashboard from './components/ResumeDashboard'

// In your pages (e.g., Dashboard.jsx)
<ResumeDashboard 
  userId={user._id} 
  apiBaseUrl="http://localhost:5000"
/>
```

## ğŸ“Š API Usage Examples

### Upload Resume
```bash
curl -X POST http://localhost:5000/api/resume/upload \
  -F "resume=@resume.pdf" \
  -F "userId=123456"
```

### Run Analysis
```bash
curl -X POST http://localhost:5000/api/resume/analyze \
  -H "Content-Type: application/json" \
  -d '{"userId": "123456"}'
```

### Get Resume Data
```bash
curl http://localhost:5000/api/resume/123456
```

## ğŸ”’ Security Features

âœ“ File type validation (PDF only)
âœ“ File size limits (5MB max)
âœ“ User association verification
âœ“ No data hallucination (only extracted data)
âœ“ Secure file storage
âœ“ Error handling without exposing sensitive info

## ğŸ“ Database Schema

User Model Extensions:
```javascript
{
  careerInfo: {
    roleType: String,
    collegeName: String,
    degree: String,
    graduationYear: Number,
    currentCompany: String,
    previousCompanies: [{companyName, role, duration}],
    yearsOfExperience: Number,
    primaryTechStack: [String],
    targetJobRole: String
  },
  resumeFile: {
    filename: String,
    uploadedAt: Date,
    filePath: String
  },
  resumeData: {
    skills: [String],
    tools: [String],
    projects: [{title, description, techStack}],
    experience: [{company, role, duration, description}],
    education: [{institution, degree, field, year}],
    certifications: [{name, issuer, date}],
    rawText: String,
    parsedAt: Date
  },
  skillAnalysis: {
    matchingSkills: [String],
    missingSkills: [String],
    suggestedSkills: [String],
    industryDemandSkills: [String],
    analysisDate: Date
  }
}
```

## ğŸ¯ Feature Workflow

1. **User Uploads Resume (PDF)**
   - File validated
   - Text extracted via pdf-parse (OCR fallback)
   - Saved to `uploads/resumes/`

2. **Automatic Parsing**
   - Text normalized & cleaned
   - Sections detected (Experience, Education, Skills, etc.)
   - Data extracted and stored

3. **User Review**
   - Views parsed data in preview
   - Can manually edit any field
   - Can add/remove items

4. **Skill Gap Analysis**
   - User's skills compared vs industry demands
   - GitHub API queries for trending skills
   - Missing skills identified
   - Learning recommendations generated
   - 4-phase roadmap created

5. **Visual Feedback**
   - Match percentage displayed
   - Categorized recommendations
   - Clear learning path provided

## ğŸ› ï¸ File Structure

```
server/
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ resume.js              # Routes & multer setup
â”‚   â””â”€â”€ resumeController.js    # Request handlers
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ resumeParserService.js # PDF parsing & extraction
â”‚   â””â”€â”€ resumeAnalyzerService.js # Skill gap analysis
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ textCleaner.js         # Text processing utilities
â”‚   â””â”€â”€ skillNormalizer.js     # Skill normalization & mapping
â””â”€â”€ models/
    â””â”€â”€ User.js                # Extended User schema

src/components/
â”œâ”€â”€ ResumeDashboard.jsx        # Main container
â”œâ”€â”€ ResumeUploadForm.jsx       # Upload interface
â”œâ”€â”€ ResumePreview.jsx          # View & edit parsed data
â”œâ”€â”€ SkillGapAnalysis.jsx       # Analysis display
â””â”€â”€ SkillRoadmap.jsx           # Learning roadmap
```

## ğŸ”„ Data Flow

```
Resume PDF
    â†“
[Upload Endpoint]
    â†“
[Parse Service] â†’ Extract Text â†’ Detect Sections â†’ Extract Data
    â†“
[Normalize] â†’ Standard Skills â†’ Store in MongoDB
    â†“
[User Sees] â†’ Preview & Can Edit
    â†“
[Analyze] â†’ Get Industry Skills â†’ Compare â†’ Generate Roadmap
    â†“
[Results] â†’ Match %, Recommendations, Learning Path
```

## âœ¨ Production Checklist

- [ ] Test PDF extraction with various resume formats
- [ ] Set up file cleanup job (remove old uploads)
- [ ] Configure GitHub API rate limits
- [ ] Add authentication to resume endpoints
- [ ] Implement file virus scanning
- [ ] Set up monitoring for parsing errors
- [ ] Cache GitHub API responses
- [ ] Add resume versioning (keep history)
- [ ] Implement resume analysis caching
- [ ] Set up email notifications on analysis completion

## ğŸš€ Next Steps

1. **Install dependencies:** `npm install`
2. **Test upload endpoint** with a sample PDF
3. **Integrate ResumeDashboard** into your dashboard page
4. **Configure GitHub token** for better skill detection
5. **Test skill gap analysis** with various job roles
6. **Customize skill mappings** based on your needs

## ğŸ“š Notes

- Skill normalization includes 100+ common variations
- GitHub API used for industry demand signals (caching recommended)
- OCR only used as fallback (slower, less accurate)
- Parsing supports multiple resume formats/styles
- Analysis results cached for 24 hours recommended
- No AI/LLM hallucination - only extracted data stored

---

**Status:** âœ… All features fully implemented and ready for testing!
